{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will see the basics of supervised machine learning with a logistic regression classifier. We will see a simple example and see how to evaluate the performance of a binary classifier and avoid over-fitting.\n",
    "# Supervised machine learning\n",
    "\n",
    "This section is partially inspired by the following Reference: https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf\n",
    "\n",
    "Supervised learning consists of inferring a function from a labeled training set. On the other hand, unsupervised learning is a machine learning technique used when the input data is not labeled. Clustering is a example of unsupervised learning. \n",
    "\n",
    "For supervised learning, we define:\n",
    "\n",
    "- The **features** (input variables) $x^{(i)}\\in \\mathbb{X}$ \n",
    "- The **target** (output we are trying to predict) $y^{(i)} \\in \\mathbb{Y}$\n",
    "\n",
    "A pair $(x^{(i)},y^{(i)})$ is a **training example**.\n",
    "\n",
    "The set $\\{(x^{(i)},y^{(i)}); i = 1,...,m\\}$ is the **training set**:\n",
    "\n",
    "The goal of supervised learning is to learn a function $h: \\mathbb{X}\\mapsto\\mathbb{Y}$, called the hypothesis, so that $h(x)$ is a good \n",
    "predictor of the corresponding $y$.\n",
    "\n",
    "- **Regression** correspond to the case where $y$ is a continuous variable\n",
    "- **Classification** correspond to the case where $y$ can only take a small number of discrete values\n",
    "\n",
    "Examples: \n",
    "- Univariate Linear Regression: $h_w(x) = w_0+w_1x$,  with $\\mathbb{X} = \\mathbb{Y} = \\mathbb{R}$\n",
    "- Multivariate Linear Regression: $$h_w(x) = w_0+w_1x_1 + ... + w_nx_n = \\sum_{i=0}^{n}w_ix_i = w^Tx,$$\n",
    "with $\\mathbb{Y} = \\mathbb{R}$ and $\\mathbb{X} = \\mathbb{R^n}$.\n",
    "Here $w_0$ is the intercept with the convention that $x_0=1$ to simplify notation.\n",
    "\n",
    "\n",
    "\n",
    "## Binary Classification with Logistic Regression\n",
    "\n",
    "- $y$ can take only two values, 0 or 1. For example, if $y$ is the sentiment associated with the tweet,\n",
    "$y=1$ if the tweet is \"positive\" and $y=0$ is the tweet is \"negative\".\n",
    "\n",
    "- $x^{(i)}$ represents the features of a tweet. For example the presence or absence of certain words.\n",
    "\n",
    "- $y^{(i)}$ is the **label** of the training example represented by $x^{(i)}$.\n",
    "\n",
    "\n",
    "Since $y\\in\\{0,1\\}$ we want to limit $h_w(x)$ between $[0,1]$.\n",
    "\n",
    "The **Logistic regression** consists of choosing $h_w(x)$ as\n",
    "\n",
    "$$\n",
    "h_w(x) = \\frac{1}{1+e^{-w^Tx}}\n",
    "$$\n",
    "\n",
    "where $w^Tx = \\sum_{i=0}^{n}w_ix_i$ and $h_w(x) = g(w^Tx)$ with\n",
    "\n",
    "$$\n",
    "g(x)=\\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "\n",
    "$g(x)$ is the **logistic function** or **sigmoid function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(-10,10)\n",
    "y = 1/(1+np.exp(-x))\n",
    "\n",
    "p = plt.plot(x,y)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $g(x)\\rightarrow 1$ for $x\\rightarrow\\infty$\n",
    "- $g(x)\\rightarrow 0$ for $x\\rightarrow -\\infty$\n",
    "- $g(0) = 1/2$\n",
    "\n",
    "Finally, to go from the regression to the classification, we can simply apply the following condition:\n",
    "\n",
    "$$\n",
    "y=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ h_w(x)>=1/2 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Let's clarify the notation. We have **$m$ training samples** and **$n$ features**, our training examples can be represented by a **$m$-by-$n$ matrix** $\\underline{\\underline{X}}=(x_{ij})$ ($m$-by-$n+1$, if we include the intercept term) that contains the training examples, $x^{(i)}$, in its rows.\n",
    "\n",
    "The target values of the training set can be represented as a $m$-dimensional vector $\\underline{y}$ and the parameters \n",
    "of our model as\n",
    "a $n$-dimensional vector $\\underline{w}$ ($n+1$ if we take into account the intercept).\n",
    "\n",
    "Now, for a given training example $x^{(i)}$, the function that we want to learn (or fit) can be written:\n",
    "\n",
    "$$\n",
    "h_\\underline{w}(x^{(i)}) = \\frac{1}{1+e^{-\\sum_{j=0}^n w_j x_{ij}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example:\n",
    "# we have 20 students that took an exam and we want to know if we can use \n",
    "# the number of hours they studied to predict if they pass or fail the\n",
    "# exam\n",
    "\n",
    "# m = 20 training samples \n",
    "# n = 1 feature (number of hours)\n",
    "\n",
    "X = np.array([0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50,\n",
    "              2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50])\n",
    "# 1 = pass, 0 = fail\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "p = plt.plot(X,y,'o')\n",
    "tx = plt.xlabel('x [h]')\n",
    "ty = plt.ylabel('y ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood of the model\n",
    "\n",
    "How to find the parameters, also called *weights*, $\\underline{w}$ that best fit our training data?\n",
    "We want to find the weights $\\underline{w}$ that maximize the likelihood of observing the target $\\underline{y}$ given the observed features $\\underline{\\underline{X}}$.\n",
    "We need a probabilistic model that gives us the probability of observing the value $y^{(i)}$ given the features $x^{(i)}$.\n",
    "\n",
    "The function $h_\\underline{w}(x^{(i)})$ can be used precisely for that:\n",
    "\n",
    "$$\n",
    "P(y^{(i)}=1|x^{(i)};\\underline{w}) = h_\\underline{w}(x^{(i)})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y^{(i)}=0|x^{(i)};\\underline{w}) = 1 - h_\\underline{w}(x^{(i)})\n",
    "$$\n",
    "\n",
    "\n",
    "we can write it more compactly as:\n",
    "\n",
    "$$\n",
    "P(y^{(i)}|x^{(i)};\\underline{w}) = (h_\\underline{w}(x^{(i)}))^{y^{(i)}} ( 1 - h_\\underline{w}(x^{(i)}))^{1-y^{(i)}}\n",
    "$$\n",
    "where $y^{(i)}\\in\\{0,1\\}$\n",
    "\n",
    "\n",
    "We see that $y^{(i)}$ is a random variable following a Bernouilli distribution with expectation $h_\\underline{w}(x^{(i)})$.\n",
    "\n",
    "\n",
    "\n",
    "The **Likelihood function** of a statistical model is defined as:\n",
    "$$\n",
    "\\mathcal{L}(\\underline{w}) = \\mathcal{L}(\\underline{w};\\underline{\\underline{X}},\\underline{y}) = P(\\underline{y}|\\underline{\\underline{X}};\\underline{w}).\n",
    "$$\n",
    "\n",
    "The likelihood takes into account all the $m$ training samples of our training dataset and estimates the likelihood \n",
    "of observing $\\underline{y}$ given $\\underline{\\underline{X}}$ and $\\underline{w}$. Assuming that the $m$ training examples were generated independently, we can write:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\underline{w}) = P(\\underline{y}|\\underline{\\underline{X}};\\underline{w}) = \\prod_{i=1}^m P(y^{(i)}|x^{(i)};\\underline{w}) = \\prod_{i=1}^m (h_\\underline{w}(x^{(i)}))^{y^{(i)}} ( 1 - h_\\underline{w}(x^{(i)}))^{1-y^{(i)}}.\n",
    "$$\n",
    "\n",
    "This is the function that we want to maximize. It is usually much simpler to maximize the logarithm of this function, which is equivalent.\n",
    "\n",
    "$$\n",
    "l(\\underline{w}) = \\log\\mathcal{L}(\\underline{w}) = \\sum_{i=1}^{m} \\left(y^{(i)} \\log h_\\underline{w}(x^{(i)}) + (1- y^{(i)})\\log\\left(1- h_\\underline{w}(x^{(i)})\\right) \\right)\n",
    "$$\n",
    "\n",
    "### Loss function and linear models\n",
    "\n",
    "An other way of formulating this problem is by defining a Loss function $L\\left(y^{(i)}, f(x^{(i)})\\right)$ such that:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{m} L\\left(y^{(i)}, f(x^{(i)})\\right) = - l(\\underline{w}).\n",
    "$$\n",
    "\n",
    "And now the problem consists of minimizing $\\sum_{i=1}^{m} L\\left(y^{(i)}, f(x^{(i)})\\right)$ over all the possible values of $\\underline{w}$.\n",
    "\n",
    "Using the definition of $h_\\underline{w}(x^{(i)})$ you can show that $L$ can be written as:\n",
    "$$\n",
    "L\\left(y^{(i)}=1, f(x^{(i)})\\right) = \\log_2\\left(1+e^{-f(x^{(i)})}\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "L\\left(y^{(i)}=0, f(x^{(i)})\\right) = \\log_2\\left(1+e^{-f(x^{(i)})}\\right) - \\log_2\\left(e^{-f(x^{(i)})}\\right)\n",
    "$$\n",
    "\n",
    "where $f(x^{(i)}) = \\sum_{j=0}^n w_j x_{ij}$ is called the **decision function**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fx = np.linspace(-5,5)\n",
    "Ly1 = np.log2(1+np.exp(-fx))\n",
    "Ly0 = np.log2(1+np.exp(-fx)) - np.log2(np.exp(-fx))\n",
    "\n",
    "p = plt.plot(fx,Ly1,label='L(1,f(x))')\n",
    "p = plt.plot(fx,Ly0,label='L(0,f(x))')\n",
    "tx = plt.xlabel('f(x)')\n",
    "ty = plt.ylabel('L')\n",
    "l = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coming back to our simple example\n",
    "\n",
    "def Loss(x_i,y_i, w0, w1):\n",
    "    fx = w0 + x_i*w1\n",
    "    \n",
    "    if y_i == 1:\n",
    "        return np.log2(1+np.exp(-fx))\n",
    "    if y_i == 0:\n",
    "        return np.log2(1+np.exp(-fx)) - np.log2(np.exp(-fx))\n",
    "    else:\n",
    "        raise Exception('y_i must be 0 or 1')\n",
    "        \n",
    "def sumLoss(x,y, w0, w1):\n",
    "    sumloss = 0\n",
    "    for x_i, y_i in zip(x,y):\n",
    "        sumloss += Loss(x_i,y_i, w0, w1)\n",
    "    return sumloss\n",
    "        \n",
    "\n",
    "# lets compute the loss function for several values\n",
    "w0s = np.linspace(-10,20,100)\n",
    "w1s = np.linspace(-10,20,100)\n",
    "\n",
    "sumLoss_vals = np.zeros((w0s.size, w1s.size))\n",
    "for k, w0 in enumerate(w0s):\n",
    "    for l, w1 in enumerate(w1s):\n",
    "        sumLoss_vals[k,l] = sumLoss(X,y,w0,w1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the values of w0 and w1 that minimize the loss\n",
    "ind0, ind1 = np.where(sumLoss_vals == sumLoss_vals.min())\n",
    "\n",
    "print('position of the minimum:', w0s[ind0], w1s[ind1])\n",
    "\n",
    "# plot the loss function\n",
    "p = plt.pcolor(w0s, w1s, sumLoss_vals, shading='auto')\n",
    "c = plt.colorbar()\n",
    "\n",
    "p2 = plt.plot(w1s[ind1], w0s[ind0], 'ro')\n",
    "\n",
    "tx = plt.xlabel('w1')\n",
    "ty = plt.ylabel('w0')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we found the minimum of the loss function simply by computing it over a large range of values. In practice, this approach is not possible when the dimensionality of the loss function (number of weights) is very large. To find the minimum of the loss function, the gradient descent algorithm (or [stochastic gradient descent](http://scikit-learn.org/stable/modules/sgd.html)) is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the solution\n",
    "\n",
    "x = np.linspace(0,6,100)\n",
    "\n",
    "def h_w(x, w0=w0s[ind0], w1=w1s[ind1]):\n",
    "    return 1/(1+np.exp(-(w0+x*w1)))\n",
    "\n",
    "p1 = plt.plot(x, h_w(x))\n",
    "p2 = plt.plot(X,y,'ro')\n",
    "tx = plt.xlabel('x [h]')\n",
    "ty = plt.ylabel('y ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of passing the exam if you worked 5 hours:\n",
    "print(h_w(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the package sci-kit learn (http://scikit-learn.org/) that provide access to many tools for machine learning, data mining and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same thing using the sklearn module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1e10)\n",
    "\n",
    "# to train our model we use the \"fit\" method\n",
    "# we have to reshape X because we have only one feature here\n",
    "model.fit(X.reshape(-1,1),y)\n",
    "\n",
    "# to see the weights\n",
    "print('w1 =', model.coef_)\n",
    "print('w0 =', model.intercept_)\n",
    "\n",
    "# use the trained model to predict new values\n",
    "print('prediction probabilities:', model.predict_proba(np.array(5).reshape(-1,1)))\n",
    "print('predicted label:', model.predict((np.array(5).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the loss function is not linear, the decision function is a **linear function of the weights and features**. This is why the Logistic regression is called a **linear model**.\n",
    "\n",
    "Other linear models are defined by different loss functions. For example:\n",
    "- Perceptron: $L \\left(y^{(i)}, f(x^{(i)})\\right) = \\max(0, -y^{(i)}\\cdot f(x^{(i)}))$\n",
    "- Hinge-loss (soft-margin Support vector machine (SVM) classification): $L \\left(y^{(i)}, f(x^{(i)})\\right) = \\max(0, 1-y^{(i)}\\cdot f(x^{(i)}))$\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/sgd.html for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fx = np.linspace(-5,5, 200)\n",
    "Logit = np.log2(1+np.exp(-fx))\n",
    "Percep = np.maximum(0,- fx) \n",
    "Hinge = np.maximum(0, 1- fx)\n",
    "ZeroOne = np.ones(fx.size)\n",
    "ZeroOne[fx>=0] = 0\n",
    "\n",
    "p = plt.plot(fx,Logit,label='Logistic Regression')\n",
    "p = plt.plot(fx,Percep,label='Perceptron')\n",
    "p = plt.plot(fx,Hinge,label='Hinge-loss')\n",
    "p = plt.plot(fx,ZeroOne,label='Zero-One loss')\n",
    "plt.xlabel('f(x)')\n",
    "plt.ylabel('L')\n",
    "plt.legend()\n",
    "ylims = plt.ylim((0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance of a binary classifier\n",
    "\n",
    "The confusion matrix allows to visualize the performance of a classifier:\n",
    "\n",
    "|          |  Predicted negative  |  Predicted positive |\n",
    "| ---    |:---:|:---:|\n",
    "| real negative | TN |  FP        |\n",
    "| real positive | FN | TP |        \n",
    "\n",
    "For each prediction $y_p$, we put it in one of the four categories based on the true value of $y$:\n",
    "- TP = True Positive\n",
    "- FP = False Positive\n",
    "- TN = True Negative\n",
    "- FN = False Negative\n",
    "\n",
    "We can then evalute several measures, for example:\n",
    "\n",
    "#### Accuracy:\n",
    "\n",
    "$\\text{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases examined. However, accuracy is not necessarily a good measure of the predictive power of a model. See the example below:\n",
    "\n",
    "#### Accuracy paradox:\n",
    "A classifier with these results:\n",
    "\n",
    "| \t|Predicted Negative | \tPredicted Positive|\n",
    "|     --- |---|---|\n",
    "|Negative Cases \t|9,700 |\t150|\n",
    "|Positive Cases \t|50 \t|100|\n",
    "\n",
    "has an accuracy = 98%.\n",
    "\n",
    "Now consider the results of a classifier that systematically predict a negative result independently of the input:\n",
    "\n",
    "| |Predicted Negative| \tPredicted Positive|\n",
    "|---|---|---|\n",
    "|Negative Cases| \t9,850 | \t0|\n",
    "|Positive Cases| \t150  |0 |\n",
    "\n",
    "The accuracy of this classifier is 98.5% while it is clearly useless. Here the less accurate model is more useful than the more accurate one. This is why accuracy should not be used (alone) to evaluate the performance of a classifier. \n",
    "Precision and Recall are usually prefered:\n",
    "\n",
    "#### Precision:\n",
    "\n",
    "$\\text{Precision}=\\frac{TP}{TP+FP}$\n",
    "\n",
    "Precision measures the fraction of correct positive or the lack of false positive.\n",
    "It answers the question: \"Given a positive prediction from the classifier, how likely is it to be correct ?\"\n",
    "\n",
    "#### Recall:\n",
    "\n",
    "$\\text{Recall}=\\frac{TP}{TP+FN}$\n",
    "\n",
    "Recall measures the proportion of positives that are correctly identified as such or the lack of false negative.\n",
    "It answers the question: \"Given a positive example, will the classifier detect it ?\"\n",
    "\n",
    "#### $F_1$ score:\n",
    "\n",
    "In order to account for the precision and recall of a classifier, $F_1$ score takes the harmonic mean of both measures:\n",
    "\n",
    "$F_1 = 2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{ \\mathrm{precision} + \\mathrm{recall}} = 2 \\frac{TP}{2TP +FP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating the performance of a classifier it is important to test is on a different set of values than then set we used to train it. Indeed, we want to know how the classifier performs on new data not on the training data. For this purpose we separate the training set in two: a part that we use to train the model and a part that we use to test it. This method is called **cross-validation**. Usually, we split the training set in N parts (typically 3 or 10), train the model on N-1 parts and test it on the remaining part. We then repeat this procedure with all the combination of training and testing parts and average the performance metrics from each tests. Sci-kit learn allows to easily perform cross-validation: http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regularization and over-fitting\n",
    "Overfitting happens when your model is too complicated to generalise for new data. When your model fits your data perfectly, it is unlikely to fit new data well.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/Overfitting.svg\" style=\"width: 250px;\"/>\n",
    "\n",
    "The model in green is over-fitted. It performs very well on the training set, but it does not generalize well to new data compared to the model in black.\n",
    "\n",
    "To avoid over-fitting, it is important to have a large training set and to use cross-validation to evaluate the performance of a model. Additionally, **regularization** is used to make the model less \"complex\" and more general.\n",
    "\n",
    "Regularization consists in adding a term $R(\\underline{w})$, that penalizes too \"complex\" models, to the loss function, so that the training error that we want to minimize is:\n",
    "\n",
    "$E(\\underline{w}) = \\sum_{i=1}^{m} L\\left(y^{(i)}, f(x^{(i)})\\right) + \\lambda R(\\underline{w})$,\n",
    "\n",
    "where $\\lambda$ is a parameter that controls the strength of the regularization.\n",
    "\n",
    "Usual choices for $R(\\underline{w})$ are:\n",
    "- L2 norm of the weights: $R(\\underline{w}) := \\frac{1}{2} \\sum_{i=1}^{n} w_j^2$, which forces small weights in the solution,\n",
    "- L1 norm of the weights: $R(\\underline{w}) := \\sum_{i=1}^{n} |w_j|$, (also refered as Lasso) which leads to sparse solutions (with several zero weights).\n",
    "\n",
    "The choice of the regularization and of the its strength are usually done by selecting the best choice during the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# logistic regression with L2 regularization, C controls the strength of the regularization\n",
    "# C = 1/lambda\n",
    "model = LogisticRegression(C=1, penalty='l2')\n",
    "\n",
    "# cross validation using 10 folds\n",
    "y_pred = cross_val_predict(model, X.reshape(-1,1), y=y, cv=10)\n",
    "\n",
    "print(confusion_matrix(y,y_pred))\n",
    "\n",
    "\n",
    "print('Accuracy = ' + str(accuracy_score(y, y_pred)))\n",
    "print('Precision = ' + str(precision_score(y, y_pred)))\n",
    "print('Recall = ' + str(precision_score(y, y_pred)))\n",
    "print('F_1 = ' + str(f1_score(y, y_pred)))\n",
    "\n",
    "# try to run it with different number of folds for the cross-validation \n",
    "# and different values of the regularization strength\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
